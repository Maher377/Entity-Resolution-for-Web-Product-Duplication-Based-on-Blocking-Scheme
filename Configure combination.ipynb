{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b4573cb",
   "metadata": {},
   "source": [
    "# Configuration combining "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f66de2",
   "metadata": {},
   "source": [
    "## Block extractor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944bb473",
   "metadata": {},
   "source": [
    "In this section we would like to performe all the block extract functions from both title and description so we can use to get the configuration set. First we import the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20f7de4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the json file\n",
    "import json\n",
    "a = open('C:\\\\\\\\Users\\\\\\\\mingh\\\\\\\\Desktop\\\\\\\\text\\\\\\\\Master\\\\\\\\Thesis\\\\\\\\Python Code\\\\\\\\Algorithm 4\\\\\\\\amazon.json')\n",
    "amazon_data = json.load(a)\n",
    "\n",
    "b = open('C:\\\\\\\\Users\\\\\\\\mingh\\\\\\\\Desktop\\\\\\\\text\\\\\\\\Master\\\\\\\\Thesis\\\\\\\\Python Code\\\\\\\\Algorithm 4\\\\\\\\bestbuy.json')\n",
    "bestbuy_data = json.load(b)\n",
    "\n",
    "c = open('C:\\\\\\\\Users\\\\\\\\mingh\\\\\\\\Desktop\\\\\\\\text\\\\\\\\Master\\\\\\\\Thesis\\\\\\\\Python Code\\\\\\\\Algorithm 4\\\\\\\\newegg.json')\n",
    "newegg_data = json.load(c)\n",
    "\n",
    "d = open('C:\\\\\\\\Users\\\\\\\\mingh\\\\\\\\Desktop\\\\\\\\text\\\\\\\\Master\\\\\\\\Thesis\\\\\\\\Python Code\\\\\\\\Algorithm 4\\\\\\\\thenerds.json')\n",
    "thenerds_data = json.load(d)\n",
    "\n",
    "data = {'amazon.com':amazon_data,'bestbuy.com':bestbuy_data,'newegg.com':newegg_data,'thenerds.net':thenerds_data}\n",
    "\n",
    "## read the json file\n",
    "f = open('C:\\\\\\\\Users\\\\\\\\mingh\\\\\\\\Desktop\\\\\\\\text\\\\\\\\Master\\\\\\\\Thesis\\\\\\\\Python Code\\\\\\\\Algorithm 3\\\\\\\\matched_mape.json')\n",
    "aligned_sheet = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c26ba7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the transformer function\n",
    "def block_transformer(block,k):\n",
    "    if k==1:\n",
    "        return block\n",
    "    else:    \n",
    "        from itertools import combinations\n",
    "        block_list = []\n",
    "        for i in combinations(block,k):\n",
    "            block_list.append(list(i))\n",
    "        return block_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2603637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the modelword check function\n",
    "def modelwords_check(inputString):\n",
    "    digit =  any(char.isdigit() for char in inputString)\n",
    "    if inputString.isnumeric():\n",
    "        non_digit = False\n",
    "    else: \n",
    "        non_digit = True\n",
    "    \n",
    "    return digit & non_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9626f5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 2), (3, 4)]\n",
      "[(1, 2), (5, 6)]\n",
      "[(3, 4), (5, 6)]\n"
     ]
    }
   ],
   "source": [
    "test = [(1,2),(3,4),(5,6)]\n",
    "test = block_transformer(test,2)\n",
    "for i in test:\n",
    "    print(str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa9fa28",
   "metadata": {},
   "source": [
    "### Title source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9c5aaa",
   "metadata": {},
   "source": [
    "#### Word extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95941f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_title(data,k):\n",
    "    Title_word_blocks = {}\n",
    "\n",
    "    # build the blocks\n",
    "    for shop in data.keys():\n",
    "        for product in data[shop].values():\n",
    "            title = product['Title'].split()\n",
    "            title = block_transformer(title,k)\n",
    "            for word in title:\n",
    "                if ','.join(word) in Title_word_blocks.keys():\n",
    "                    Title_word_blocks[','.join(word)].append({'title':product['Title'],'shop':shop,'ID':product['model_ID']})\n",
    "                else:\n",
    "                    Title_word_blocks[','.join(word)] = [{'title':product['Title'],'shop':shop,'ID':product['model_ID']}]\n",
    "\n",
    "\n",
    "\n",
    "    # prepare the parameter that we used for evaluation\n",
    "    block_count_word = len(Title_word_blocks.keys())\n",
    "    avg_product_count_word = 0\n",
    "    max_product_count_word = 0\n",
    "    for block in Title_word_blocks.values():\n",
    "        avg_product_count_word += len(block)\n",
    "\n",
    "        if len(block)>max_product_count_word:\n",
    "            max_product_count_word = len(block)\n",
    "        else: pass\n",
    "\n",
    "    avg_product_count_word = avg_product_count_word/block_count_word\n",
    "    \n",
    "    return(Title_word_blocks,block_count_word,avg_product_count_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fab3c0e",
   "metadata": {},
   "source": [
    "#### Modelword extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ebc920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelword_title(data,k):\n",
    "    import re\n",
    "    Title_modelword_blocks = {}\n",
    "\n",
    "    # build the blocks\n",
    "    for shop in data.keys():\n",
    "        for product in data[shop].values():\n",
    "            title_raw = product['Title'].split()\n",
    "            title = []\n",
    "            for word in title_raw:\n",
    "                if modelwords_check(word):\n",
    "                    title.append(word)\n",
    "                else: pass\n",
    "            title = block_transformer(title,k)\n",
    "            for word in title:\n",
    "                if ','.join(word) in Title_modelword_blocks.keys():\n",
    "                    Title_modelword_blocks[','.join(word)].append({'title':product['Title'],'shop':shop,'ID':product['model_ID']})\n",
    "                else:\n",
    "                    Title_modelword_blocks[','.join(word)] = [{'title':product['Title'],'shop':shop,'ID':product['model_ID']}]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # prepare the parameter that we used for evaluation\n",
    "    block_count_modelword = len(Title_modelword_blocks.keys())\n",
    "    avg_product_count_modelword = 0\n",
    "    max_product_count_modelword = 0\n",
    "    for block in Title_modelword_blocks.values():\n",
    "        avg_product_count_modelword += len(block)\n",
    "\n",
    "        if len(block)>max_product_count_modelword:\n",
    "            max_product_count_modelword = len(block)\n",
    "        else: pass\n",
    "\n",
    "    avg_product_count_modelword = avg_product_count_modelword/block_count_modelword\n",
    "    return(Title_modelword_blocks,block_count_modelword,avg_product_count_modelword)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fcbd71",
   "metadata": {},
   "source": [
    "#### Q-gram extractor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "290f2bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qgram_title(data,n = 3,k=1):\n",
    "    from nltk import ngrams\n",
    "    # define the required value\n",
    "    Title_qgram_blocks = {}\n",
    "\n",
    "    # build the blocks\n",
    "    for shop in data.keys():\n",
    "        for product in data[shop].values():\n",
    "            title = ngrams(product['Title'].split(), n)\n",
    "            title = block_transformer(title,k)\n",
    "            for word in title:\n",
    "                if word[0] in Title_qgram_blocks.keys():\n",
    "                    Title_qgram_blocks[','.join(word[0])].append({'title':product['Title'],'shop':shop,'ID':product['model_ID']})\n",
    "                else:\n",
    "                    Title_qgram_blocks[','.join(word[0])] = [{'title':product['Title'],'shop':shop,'ID':product['model_ID']}]\n",
    "\n",
    "\n",
    "\n",
    "    # prepare the parameter that we used for evaluation\n",
    "    block_count_qgram = len(Title_qgram_blocks.keys())\n",
    "    avg_product_count_qgram = 0\n",
    "    max_product_count_qgram = 0\n",
    "    for block in Title_qgram_blocks.values():\n",
    "        avg_product_count_qgram += len(block)\n",
    "\n",
    "        if len(block)>max_product_count_qgram:\n",
    "            max_product_count_qgram = len(block)\n",
    "        else: pass\n",
    "\n",
    "    avg_product_count_qgram = avg_product_count_qgram/block_count_qgram\n",
    "    \n",
    "    return(Title_qgram_blocks,block_count_qgram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33456ac1",
   "metadata": {},
   "source": [
    "#### Skip-gram extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe789690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skipgram_title(data,window_size = 2):\n",
    "    from itertools import combinations\n",
    "    import string\n",
    "\n",
    "    # define the required value\n",
    "    Title_skip_blocks = {}\n",
    "    # build the blocks\n",
    "    for shop in data.keys():\n",
    "        for product in data[shop].values():\n",
    "            # here we build the skip-gram combinations\n",
    "            pairs_for_all_sentences = []\n",
    "            title_clean = product['Title'].translate(str.maketrans('', '', string.punctuation))\n",
    "            title = [title_clean.split()]\n",
    "            for sentence in title:\n",
    "                this_sentence_pairs = []\n",
    "\n",
    "                for index, target_word in enumerate(sentence): \n",
    "                    window_words = sentence[max(index - window_size, 0) : min(index + window_size + 1, len(sentence))]\n",
    "\n",
    "                    for window_word in window_words:\n",
    "                        if window_word != target_word:\n",
    "                            this_sentence_pairs.append((window_word, target_word))\n",
    "\n",
    "                pairs_for_all_sentences.append(this_sentence_pairs)\n",
    "            title = pairs_for_all_sentences[0]\n",
    "\n",
    "\n",
    "            for word in title:\n",
    "                if word in Title_skip_blocks.keys():\n",
    "                    Title_skip_blocks[word].append({'title':product['Title'],'shop':shop,'ID':product['model_ID']})\n",
    "                else:\n",
    "                    Title_skip_blocks[word] = [{'title':product['Title'],'shop':shop,'ID':product['model_ID']}]\n",
    "\n",
    "\n",
    "\n",
    "    # prepare the parameter that we used for evaluation\n",
    "    block_count_skip = len(Title_skip_blocks.keys())\n",
    "    avg_product_count_skip = 0\n",
    "    max_product_count_skip = 0\n",
    "    for block in Title_skip_blocks.values():\n",
    "        avg_product_count_skip += len(block)\n",
    "\n",
    "        if len(block)>max_product_count_skip:\n",
    "            max_product_count_skip = len(block)\n",
    "        else: pass\n",
    "\n",
    "    avg_product_count_skip = avg_product_count_skip/block_count_skip\n",
    "    \n",
    "    return(Title_skip_blocks,block_count_skip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32f3ed0",
   "metadata": {},
   "source": [
    "#### Suffix array extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b42542f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suffix_title(data):\n",
    "    # define the required value\n",
    "    Title_suffix_blocks = {}\n",
    "\n",
    "    # build the blocks\n",
    "    for shop in data.keys():\n",
    "        for product in data[shop].values():\n",
    "            title = product['Title'].split()\n",
    "            title = sorted([title[i:], i] for i in range(len(title)))\n",
    "            for suffix in title:\n",
    "                suffix_str = str(suffix)\n",
    "                if suffix_str in Title_suffix_blocks.keys():\n",
    "                    Title_suffix_blocks[suffix_str].append({'title':product['Title'],'shop':shop,'ID':product['model_ID']})\n",
    "                else:\n",
    "                    Title_suffix_blocks[suffix_str] = [{'title':product['Title'],'shop':shop,'ID':product['model_ID']}]\n",
    "\n",
    "\n",
    "\n",
    "    # prepare the parameter that we used for evaluation\n",
    "    block_count_suffix = len(Title_suffix_blocks.keys())\n",
    "    avg_product_count_suffix = 0\n",
    "    max_product_count_suffix = 0\n",
    "    for block in Title_suffix_blocks.values():\n",
    "        avg_product_count_suffix += len(block)\n",
    "\n",
    "        if len(block)>max_product_count_suffix:\n",
    "            max_product_count_suffix = len(block)\n",
    "        else: pass\n",
    "\n",
    "    avg_product_count_suffix = avg_product_count_suffix/block_count_suffix\n",
    "    \n",
    "    return(Title_suffix_blocks,block_count_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9341a7",
   "metadata": {},
   "source": [
    "### Description source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72b0a615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to find all the matched keys of a specific key\n",
    "def matched_key(shop1,key1):\n",
    "    key_set = [key1]\n",
    "    for shop in aligned_sheet[shop1][key1].values():\n",
    "        if shop['score']>0.28:\n",
    "            key_set.append(shop['key'])\n",
    "            \n",
    "    key_set.sort()        \n",
    "    return(key_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05944949",
   "metadata": {},
   "source": [
    "#### Word extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "094cd824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_KVP(data,k=1):\n",
    "    # define the required value\n",
    "    KVP_word_blocks = {}\n",
    "\n",
    "    # build the blocks\n",
    "    for shop in data.keys():\n",
    "        for product in data[shop].values():\n",
    "            key_value = []\n",
    "            for value in product['featuresMap'].keys():\n",
    "                value_split = product['featuresMap'][value].split()  \n",
    "                block = block_transformer(value_split,k)\n",
    "                for word in block:\n",
    "                    if word in key_value:\n",
    "                        pass\n",
    "                    else:\n",
    "                        key_value.append(word)\n",
    "                        \n",
    "            for word in key_value:\n",
    "                if str(word) in KVP_word_blocks.keys():\n",
    "\n",
    "                    KVP_word_blocks[str(word)].append({'title':product['Title'],'shop':shop,'ID':product['model_ID']})\n",
    "                else:\n",
    "\n",
    "                    KVP_word_blocks[str(word)] = [{'title':product['Title'],'shop':shop,'ID':product['model_ID']}]\n",
    "\n",
    "\n",
    "    # prepare the parameter that we used for evaluation\n",
    "    block_count_word = len(KVP_word_blocks.keys())\n",
    "    avg_product_count_word = 0\n",
    "    max_product_count_word = 0\n",
    "    for block in KVP_word_blocks.values():\n",
    "        avg_product_count_word += len(block)\n",
    "\n",
    "        if len(block)>max_product_count_word:\n",
    "            max_product_count_word = len(block)\n",
    "        else: pass\n",
    "\n",
    "    avg_product_count_word = avg_product_count_word/block_count_word\n",
    "    return(KVP_word_blocks,block_count_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa294bb",
   "metadata": {},
   "source": [
    "#### Modelword extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f354de0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelword_KVP(data,k=1):\n",
    "    # define the required value\n",
    "    KVP_modelword_blocks = {}\n",
    "\n",
    "    # build the blocks\n",
    "    for shop in data.keys():\n",
    "        rest_shop = list(data.keys()).remove(shop)\n",
    "        for product in data[shop].values():\n",
    "            modelword_list = []\n",
    "            key_value = []\n",
    "            for value in product['featuresMap'].keys():\n",
    "                value_block = []\n",
    "                value_split = product['featuresMap'][value].split()  \n",
    "                for word in value_split:\n",
    "                    if modelwords_check(word):\n",
    "                        modelword_list.append(word)\n",
    "                \n",
    "                modelword_list = block_transformer(modelword_list,k)\n",
    "                for block in modelword_list:\n",
    "                    if block in key_value:\n",
    "                        pass\n",
    "                    else:\n",
    "                        key_value.append(block)\n",
    "                        \n",
    "            for word in key_value:\n",
    "                if str(word) in KVP_modelword_blocks.keys():\n",
    "\n",
    "                    KVP_modelword_blocks[str(word)].append({'title':product['Title'],'shop':shop,'ID':product['model_ID']})\n",
    "                else:\n",
    "\n",
    "                    KVP_modelword_blocks[str(word)] = [{'title':product['Title'],'shop':shop,'ID':product['model_ID']}]\n",
    "\n",
    "\n",
    "\n",
    "    # prepare the parameter that we used for evaluation\n",
    "    block_count_modelword = len(KVP_modelword_blocks.keys())\n",
    "    avg_product_count_modelword = 0\n",
    "    max_product_count_modelword = 0\n",
    "    for block in KVP_modelword_blocks.values():\n",
    "        avg_product_count_modelword += len(block)\n",
    "\n",
    "        if len(block)>max_product_count_modelword:\n",
    "            max_product_count_modelword = len(block)\n",
    "        else: pass\n",
    "\n",
    "    avg_product_count_modelword = avg_product_count_modelword/block_count_modelword\n",
    "    return(KVP_modelword_blocks,block_count_modelword)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cfc31e",
   "metadata": {},
   "source": [
    "#### Q-gram extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd2141d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qgram_KVP(data):\n",
    "    from nltk import ngrams\n",
    "\n",
    "    # define the required value\n",
    "    KVP_qgram_blocks = {}\n",
    "    n=3\n",
    "\n",
    "    # build the blocks\n",
    "    for shop in data.keys():\n",
    "        for product in data[shop].values():\n",
    "            key_value = []\n",
    "            for value in product['featuresMap'].keys():\n",
    "                value_split = ngrams(product['featuresMap'][value].split(),n)\n",
    "                for ngram in value_split:\n",
    "                    key_value.append(ngram)\n",
    "\n",
    "            for word in key_value:\n",
    "                if ','.join(word) in KVP_qgram_blocks.keys():\n",
    "                    KVP_qgram_blocks[','.join(word)].append({'title':product['Title'],'shop':shop,'ID':product['model_ID']})\n",
    "                else:\n",
    "                    KVP_qgram_blocks[','.join(word)] = [{'title':product['Title'],'shop':shop,'ID':product['model_ID']}]\n",
    "\n",
    "\n",
    "    # prepare the parameter that we used for evaluation\n",
    "    block_count_qgram = len(KVP_qgram_blocks.keys())\n",
    "    avg_product_count_qgram = 0\n",
    "    max_product_count_qgram = 0\n",
    "    for block in KVP_qgram_blocks.values():\n",
    "        avg_product_count_qgram += len(block)\n",
    "\n",
    "        if len(block)>max_product_count_qgram:\n",
    "            max_product_count_qgram = len(block)\n",
    "        else: pass\n",
    "\n",
    "    avg_product_count_qgram = avg_product_count_qgram/block_count_qgram\n",
    "    \n",
    "    return(KVP_qgram_blocks,block_count_qgram)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b876c0",
   "metadata": {},
   "source": [
    "#### Skip-gram extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e988f4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skipgram_KVP(data):\n",
    "    from itertools import combinations\n",
    "    import string\n",
    "\n",
    "    # define the required value\n",
    "    KVP_skip_blocks = {}\n",
    "    window_size = 2 # here we define the length of the window we would focus when we extract information from the strings\n",
    "\n",
    "    # build the blocks\n",
    "    for shop in data.keys():\n",
    "        for product in data[shop].values():\n",
    "            # here we build the skip-gram combinations\n",
    "            pairs_for_all_sentences = []\n",
    "            key_value = []\n",
    "            for value in product['featuresMap'].keys():\n",
    "                value_clean = product['featuresMap'][value].translate(str.maketrans('', '', string.punctuation))\n",
    "                value_split = [value_clean.split()]\n",
    "                for word in value_split:\n",
    "                    key_value.append(word)\n",
    "\n",
    "            for sentence in key_value:\n",
    "                this_sentence_pairs = []\n",
    "\n",
    "            for index, target_word in enumerate(sentence): \n",
    "                window_words = sentence[max(index - window_size, 0) : min(index + window_size + 1, len(sentence))]\n",
    "                for window_word in window_words:\n",
    "                    if window_word != target_word:\n",
    "                        this_sentence_pairs.append((window_word, target_word))\n",
    "\n",
    "            pairs_for_all_sentences.append(this_sentence_pairs)\n",
    "\n",
    "            for i in pairs_for_all_sentences:\n",
    "                for combination in i:\n",
    "                    key_value.append([value,str(combination)])\n",
    "\n",
    "\n",
    "            for word in key_value:\n",
    "                if ','.join(word) in KVP_skip_blocks.keys():\n",
    "\n",
    "                    KVP_skip_blocks[','.join(word)].append({'title':product['Title'],'shop':shop,'ID':product['model_ID']})\n",
    "                else:\n",
    "\n",
    "                    KVP_skip_blocks[','.join(word)] = [{'title':product['Title'],'shop':shop,'ID':product['model_ID']}]\n",
    "\n",
    "\n",
    "\n",
    "    # prepare the parameter that we used for evaluation\n",
    "    block_count_skip = len(KVP_skip_blocks.keys())\n",
    "    avg_product_count_skip = 0\n",
    "    max_product_count_skip = 0\n",
    "    for block in KVP_skip_blocks.values():\n",
    "        avg_product_count_skip += len(block)\n",
    "\n",
    "        if len(block)>max_product_count_skip:\n",
    "            max_product_count_skip = len(block)\n",
    "        else: pass\n",
    "\n",
    "    avg_product_count_skip = avg_product_count_skip/block_count_skip\n",
    "    \n",
    "    return(KVP_skip_blocks,block_count_skip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2da79f5",
   "metadata": {},
   "source": [
    "#### Suffix array extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e81d2ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suffix_KVP(data):\n",
    "    # define the required value\n",
    "    KVP_suffix_blocks = {}\n",
    "\n",
    "    # build the blocks\n",
    "    for shop in data.keys():\n",
    "        for product in data[shop].values():\n",
    "            key_value = []\n",
    "            for value in product['featuresMap'].values():\n",
    "                value_split = value.split()\n",
    "                value_split = sorted([value_split[i:], i] for i in range(len(value_split)))\n",
    "                for word in value_split:\n",
    "                    key_value.append(word)\n",
    "\n",
    "            for suffix in key_value:\n",
    "                suffix_str = str(suffix)\n",
    "                if suffix_str in KVP_suffix_blocks.keys():\n",
    "                    KVP_suffix_blocks[suffix_str].append({'title':product['Title'],'shop':shop,'ID':product['model_ID']})\n",
    "                else:\n",
    "                    KVP_suffix_blocks[suffix_str] = [{'title':product['Title'],'shop':shop,'ID':product['model_ID']}]\n",
    "\n",
    "\n",
    "\n",
    "    # prepare the parameter that we used for evaluation\n",
    "    block_count_suffix = len(KVP_suffix_blocks.keys())\n",
    "    avg_product_count_suffix = 0\n",
    "    max_product_count_suffix = 0\n",
    "    for block in KVP_suffix_blocks.values():\n",
    "        avg_product_count_suffix += len(block)\n",
    "\n",
    "        if len(block)>max_product_count_suffix:\n",
    "            max_product_count_suffix = len(block)\n",
    "        else: pass\n",
    "\n",
    "    avg_product_count_suffix = avg_product_count_suffix/block_count_suffix\n",
    "    return(KVP_suffix_blocks,block_count_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3eaa28",
   "metadata": {},
   "source": [
    "## Data merger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308c379b",
   "metadata": {},
   "source": [
    "### Combine with the original data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b16843",
   "metadata": {},
   "source": [
    "In this section we merge the result of the blocking schemas with the original data, so as the result each product in the original data should contains one more variable called 'matched product'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "417aa4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initical a dataset based on the block schema\n",
    "\n",
    "def data_initical(block_schema):\n",
    "    import copy\n",
    "    output_data = copy.deepcopy(data)\n",
    "    \n",
    "    for shop in output_data.keys():\n",
    "        for product_this in output_data[shop].values():\n",
    "            product_this['matched product'] = []\n",
    "            for block in block_schema.keys():\n",
    "                block_check = False\n",
    "\n",
    "                for product_block in block_schema[block]:\n",
    "                    if product_this['Title'] == product_block['title'] and product_this['model_ID'] == product_block['ID'] and shop == product_block['shop'] :\n",
    "                        block_check = True\n",
    "\n",
    "\n",
    "                if block_check == True:\n",
    "                    for i in block_schema[block]:\n",
    "                        if i['shop'] == shop:\n",
    "                            pass\n",
    "                        else:   # in case we count same product several times as paired product\n",
    "                            if i in product_this['matched product']:\n",
    "                                pass\n",
    "                            else:\n",
    "                                product_this['matched product'].append(i)\n",
    "                                \n",
    "                \n",
    "    return(output_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a826e131",
   "metadata": {},
   "source": [
    "### Block aggregation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbb50f8",
   "metadata": {},
   "source": [
    "#### Union "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "ba87279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Union(dataset_1,dataset_2):\n",
    "    import copy\n",
    "    Output = copy.deepcopy(dataset_1)\n",
    "    \n",
    "    for shop in Output.keys():\n",
    "        for product_this in Output[shop].values():\n",
    "            matched_pair_1 = list(product_this['matched product'])\n",
    "            matched_pair_2 = list(dataset_2[shop][product_this['model_ID']]['matched product'])\n",
    "            matched_pair = matched_pair_1 + matched_pair_2\n",
    "            uniq = []\n",
    "            [uniq.append(x) for x in matched_pair if x not in uniq]\n",
    "\n",
    "            product_this['matched product'] = uniq\n",
    "            \n",
    "    return(Output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bdc244",
   "metadata": {},
   "source": [
    "#### Conjunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "06354a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first set a function to find the common element in two list\n",
    "def common_elements(list1, list2):\n",
    "    return [element for element in list1 if element in list2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "a9cefa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conjunction(dataset_1,dataset_2):\n",
    "    import copy\n",
    "    Output = copy.deepcopy(dataset_1)\n",
    "    \n",
    "    for shop in Output.keys():\n",
    "        for product_this in Output[shop].values():\n",
    "            \n",
    "            matched_pair_1 = list(product_this['matched product'])\n",
    "            matched_pair_2 = list(dataset_2[shop][product_this['model_ID']]['matched product'])\n",
    "                \n",
    "            \n",
    "            product_this['matched product'] = common_elements(matched_pair_1,matched_pair_2)\n",
    "            \n",
    "    return(Output)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13a5ea5",
   "metadata": {},
   "source": [
    "##  Configuration building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c500af4c",
   "metadata": {},
   "source": [
    "Now we propose the possible configuration that we would like to further discuss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "5984a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration_low = [['t_mw',3,'d_skip','conjunction'],['t_mw',3,'d_suffix','conjunction'],['t_mw',4,'d_qgram','union'],['t_wo',3,'d_wo','conjunction'],['t_mw',3,'d_mw','conjunction']]\n",
    "configuration_mid = [['t_mw',2,'d_skip','conjunction'],['t_mw',3,'d_qgram','union'],['t_wo',4,'d_skip','conjunction'],['t_wo',3,'d_mw','conjunction'],['t_mw',2,'d_wo','conjunction'],['t_qgram','d_mw','conjunction']]\n",
    "configuration_high = [['t_mw',2,'d_skip','union'],['t_mw',2,'d_qgram','union'],['t_wo',2,'d_suffix','union'],['t_mw',3,'d_wo','union'],['t_skip','d_wo','union']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "db479b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in configuration_3:\n",
    "    if i[0] == 't_mw':\n",
    "        result1,count1 = modelword_title(data,i[1])\n",
    "    elif i[0] == 't_wo':\n",
    "        result1,count1 = word_title(data,i[1])\n",
    "    elif i[0] == 't_skip':\n",
    "        result1,count1 = skipgram_title(data)\n",
    "        \n",
    "    if i[2] == 'd_mw':\n",
    "        result2,count2 = modelword_KVP(data)\n",
    "    elif i[2] == 'd_wo':\n",
    "        result2,count2 = word_KVP(data)\n",
    "        \n",
    "\n",
    "    import json\n",
    "    name_union = i[0]+str(i[1])+'_'+i[2] +'_union.json'   \n",
    "    name_conjunction = i[0]+str(i[1])+'_'+i[2] +'_conjunction.json'\n",
    "    with open(name_union, 'w') as u:\n",
    "        json.dump(union_set, u)    \n",
    "    with open(name_conjunction, 'w') as c:\n",
    "        json.dump(conjunction_set, c)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4acfcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in configuration_2:\n",
    "    if i[0] == 't_qgram':\n",
    "        result1,count1 = skipgram_title(data)\n",
    "    elif i[0] == 't_suffix':\n",
    "        result1,count1 = suffix_title(data)\n",
    "    elif i[0] == 't_skip':\n",
    "        result1,count1 = qgram_title(data)\n",
    "        \n",
    "    if i[1] == 'd_mw':\n",
    "        result2,count2 = modelword_KVP(data)\n",
    "    elif i[1] == 'd_wo':\n",
    "        result2,count2 = word_KVP(data)\n",
    "        \n",
    "    data_title = data_initical(result1)\n",
    "    data_KVP = data_initical(result2)\n",
    "\n",
    "\n",
    "    conjunction_set_2 = Conjunction(data_title,data_KVP)\n",
    "        \n",
    "    name_conjunction_2 = i[0]+'_'+i[1] +'_conjunction.json'\n",
    "    with open(name_conjunction_2, 'w') as c:\n",
    "        json.dump(conjunction_set_2, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba23f38",
   "metadata": {},
   "source": [
    "# Test area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f455be45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=1, microseconds=659714)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "tstart = datetime.datetime.now()\n",
    "\n",
    "\n",
    "result1,count1,avg_product_count_modelword = modelword_title(data,4)\n",
    "\n",
    "tend = datetime.datetime.now()\n",
    "duration = tend - tstart\n",
    "duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0b66ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3188303681521931"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_product_count_modelword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "ea8e620d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5049"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "tstart = datetime.datetime.now()\n",
    "\n",
    "\n",
    "result2,count2 = modelword_title(data,2)\n",
    "\n",
    "tend = datetime.datetime.now()\n",
    "duration = tend - tstart\n",
    "duration\n",
    "count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "de2f9d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(microseconds=250028)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e36bdc1",
   "metadata": {},
   "source": [
    "### Aggregation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "82502702",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_title = data_initical(result1)\n",
    "data_KVP = data_initical(result2)\n",
    "\n",
    "t_wo2_d_skip_union = Union(data_title,data_KVP)\n",
    "t_wo2_d_skip_conjunction = Conjunction(data_title,data_KVP)\n",
    "\n",
    "import json\n",
    "\n",
    "with open('t_wo2_d_skip_union.json', 'w') as u:\n",
    "    json.dump(t_wo2_d_skip_union, u)\n",
    "    \n",
    "with open('t_wo2_d_skip_conjunction.json', 'w') as c:\n",
    "    json.dump(t_wo2_d_skip_conjunction, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "c383749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_title = data_initical(result1)\n",
    "data_KVP = data_initical(result2)\n",
    "\n",
    "t_wo2_d_skip_union = Union(data_title,data_KVP)\n",
    "t_wo2_d_skip_conjunction = Conjunction(data_title,data_KVP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "b88f6c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t_wo2_d_skip_union['amazon.com']['UN46ES6580']['matched product'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "98efbfa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t_wo2_d_skip_conjunction['amazon.com']['UN46ES6580']['matched product'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
